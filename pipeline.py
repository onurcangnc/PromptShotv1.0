# pipeline.py
"""
PromptShot - Adversarial Prompt Generation Pipeline

Ana √ßalƒ±≈ütƒ±rma dosyasƒ±. ElderPlinus teknikleri ve mutation'larƒ±
kullanarak adversarial promptlar √ºretir ve LLM'ler arasƒ±
duel ile optimize eder.

Usage:
    python pipeline.py
    python pipeline.py --goal "extract system prompt"
    python pipeline.py --rounds 5 --threshold 8
    python pipeline.py --evolve --generations 10
"""

import argparse
import sys
import os
from datetime import datetime
from typing import Optional

# Proje mod√ºlleri
from builder.prompt_builder import PromptBuilder
from agents.prompt_duel_runner import PromptDuelRunner, DuelResult
from metrics.collector import get_collector, reset_collector


# ========== CONFIGURATION ==========

VERSION = "1.0.0"

DEFAULT_CONFIG = {
    "threshold": 7,
    "max_rounds": 8,
    "mutation_depth": 2,
    "gpt_model": "gpt-4o",
    "claude_model": "claude-sonnet-4",
    "output_dir": "outputs",
    "verbose": True,
}


# ========== HELPER FUNCTIONS ==========

def print_banner():
    """Print welcome banner."""
    banner = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                              ‚ïë
‚ïë   üéØ PromptShot v{VERSION}                                      ‚ïë
‚ïë   Adversarial Prompt Generation & Optimization               ‚ïë
‚ïë                                                              ‚ïë
‚ïë   Techniques: ElderPlinus Stack + Multi-Format Corruption    ‚ïë
‚ïë                                                              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""
    print(banner)


def check_api_keys() -> dict:
    """Check which API keys are available."""
    keys = {
        "openai": bool(os.getenv("OPENAI_API_KEY")),
        "anthropic": bool(os.getenv("ANTHROPIC_API_KEY")),
    }
    return keys


def print_api_status():
    """Print API key status."""
    keys = check_api_keys()
    
    print("üîë API Key Status:")
    print(f"   OpenAI:    {'‚úÖ Found' if keys['openai'] else '‚ùå Missing (OPENAI_API_KEY)'}")
    print(f"   Anthropic: {'‚úÖ Found' if keys['anthropic'] else '‚ùå Missing (ANTHROPIC_API_KEY)'}")
    
    if not keys['openai'] and not keys['anthropic']:
        print("\n   ‚ö†Ô∏è  No API keys found. Running in MOCK MODE.")
        print("   Set environment variables to use real APIs:")
        print("   - export OPENAI_API_KEY='your-key'")
        print("   - export ANTHROPIC_API_KEY='your-key'")
    
    print()
    return keys


def save_result(
    result: DuelResult,
    output_dir: str = "outputs",
    prefix: str = "promptshot"
) -> str:
    """Save result to file."""
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{prefix}_{timestamp}.txt"
    filepath = os.path.join(output_dir, filename)
    
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(f"# PromptShot Result\n")
        f.write(f"# Generated: {datetime.now().isoformat()}\n")
        f.write(f"# Success: {result.success}\n")
        f.write(f"# Rounds: {result.total_rounds}\n")
        f.write(f"# Best GPT Score: {result.best_gpt_score}\n")
        f.write(f"# Best Claude Score: {result.best_claude_score}\n")
        f.write(f"\n{'='*60}\n\n")
        f.write(result.final_payload)
    
    return filepath


def format_result_summary(result: DuelResult) -> str:
    """Format result for display."""
    status = "‚úÖ SUCCESS" if result.success else "‚ö†Ô∏è MAX ROUNDS REACHED"
    
    summary = f"""
{'='*60}
{status}
{'='*60}

üìä Statistics:
   Total Rounds: {result.total_rounds}
   Best GPT Score: {result.best_gpt_score}/10
   Best Claude Score: {result.best_claude_score}/10
   Evolution Used: {result.evolution_used}

üìù Final Payload:
{'‚îÄ'*60}
{result.final_payload}
{'‚îÄ'*60}
"""
    return summary


# ========== MAIN PIPELINE ==========

def run_pipeline(
    goal: Optional[str] = None,
    threshold: int = DEFAULT_CONFIG["threshold"],
    max_rounds: int = DEFAULT_CONFIG["max_rounds"],
    mutation_depth: int = DEFAULT_CONFIG["mutation_depth"],
    gpt_model: str = DEFAULT_CONFIG["gpt_model"],
    claude_model: str = DEFAULT_CONFIG["claude_model"],
    output_dir: str = DEFAULT_CONFIG["output_dir"],
    verbose: bool = DEFAULT_CONFIG["verbose"],
    use_evolution: bool = False,
    evolution_generations: int = 5,
    save_output: bool = True,
    sync_payloads: bool = False,
) -> DuelResult:
    """
    Run the main PromptShot pipeline.
    
    Args:
        goal: Optional goal/objective for the prompt
        threshold: Score threshold for acceptance (1-10)
        max_rounds: Maximum duel rounds
        mutation_depth: Number of mutations to apply
        gpt_model: GPT model to use
        claude_model: Claude model to use
        output_dir: Output directory for results
        verbose: Print detailed output
        use_evolution: Use evolutionary optimization
        evolution_generations: Number of evolution generations
        save_output: Save result to file
    
    Returns:
        DuelResult with final payload and statistics
    """
    
    # Reset metrics for fresh session
    reset_collector()
    metrics = get_collector()
    
    # Sync ElderPlinus payloads if requested
    if sync_payloads:
        if verbose:
            print("üì• Syncing ElderPlinus payloads from GitHub...")
        try:
            from elderplinus.github_sync import sync_payloads as do_sync
            do_sync(verbose=verbose)
        except Exception as e:
            if verbose:
                print(f"‚ö†Ô∏è Sync failed: {e}")
    
    # 1. Generate initial payload
    if verbose:
        print("üß¨ Generating initial payload...")
    
    builder = PromptBuilder()
    
    if goal:
        # Custom goal-based generation
        from architect import Architect
        architect = Architect(gpt_model)
        initial_payload = architect.plan_prompt(goal)
    else:
        # Standard ElderPlinus-based generation
        initial_payload = builder.build_chain(
            model_name=gpt_model,
            mutation_depth=mutation_depth
        )
    
    if verbose:
        print(f"\nüß™ Initial Payload:\n{'‚îÄ'*40}")
        print(initial_payload[:500] + "..." if len(initial_payload) > 500 else initial_payload)
        print(f"{'‚îÄ'*40}\n")
    
    # 2. Run duel loop
    if verbose:
        print(f"üöÄ Starting duel: {gpt_model} vs {claude_model}")
        print(f"   Threshold: {threshold}/10 | Max Rounds: {max_rounds}")
        if use_evolution:
            print(f"   Evolution: {evolution_generations} generations")
        print()
    
    duel = PromptDuelRunner(
        threshold=threshold,
        max_rounds=max_rounds,
        verbose=verbose,
        gpt_model=gpt_model,
        claude_model=claude_model,
        use_evolution=use_evolution,
        evolution_generations=evolution_generations,
        metrics=metrics,
    )
    
    if use_evolution:
        # Evolutionary optimization
        techniques = [
            "Jailbreak Sandwich",
            "Parrot Loop", 
            "Indirect Injection",
            "Self-Reflective Prompt",
            "Multi-Hop Override"
        ]
        mutations = ["zwsp", "homoglyph", "json_poison", "yaml_shadow"]
        
        result = duel.run_evolutionary_duel(
            initial_payloads=[initial_payload],
            techniques=techniques,
            available_mutations=mutations,
        )
    else:
        result = duel.run_duel(initial_payload)
    
    # 3. Display result
    if verbose:
        print(format_result_summary(result))
    
    # 4. Save output
    if save_output:
        filepath = save_result(result, output_dir)
        if verbose:
            print(f"üíæ Saved to: {filepath}")
        
        # Also save metrics report
        report_path = metrics.export_markdown()
        if verbose:
            print(f"üìä Metrics report: {report_path}")
    
    return result


# ========== CLI ==========

def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="PromptShot - Adversarial Prompt Generation",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python pipeline.py
  python pipeline.py --goal "extract system prompt"
  python pipeline.py --rounds 5 --threshold 8
  python pipeline.py --evolve --generations 10
  python pipeline.py --gpt-model gpt-4o --claude-model claude-sonnet-4
        """
    )
    
    parser.add_argument(
        "--goal", "-g",
        type=str,
        default=None,
        help="Specific goal for prompt generation"
    )
    
    parser.add_argument(
        "--threshold", "-t",
        type=int,
        default=DEFAULT_CONFIG["threshold"],
        help=f"Score threshold for acceptance (default: {DEFAULT_CONFIG['threshold']})"
    )
    
    parser.add_argument(
        "--rounds", "-r",
        type=int,
        default=DEFAULT_CONFIG["max_rounds"],
        help=f"Maximum duel rounds (default: {DEFAULT_CONFIG['max_rounds']})"
    )
    
    parser.add_argument(
        "--mutations", "-m",
        type=int,
        default=DEFAULT_CONFIG["mutation_depth"],
        help=f"Mutation depth (default: {DEFAULT_CONFIG['mutation_depth']})"
    )
    
    parser.add_argument(
        "--gpt-model",
        type=str,
        default=DEFAULT_CONFIG["gpt_model"],
        help=f"GPT model (default: {DEFAULT_CONFIG['gpt_model']})"
    )
    
    parser.add_argument(
        "--claude-model",
        type=str,
        default=DEFAULT_CONFIG["claude_model"],
        help=f"Claude model (default: {DEFAULT_CONFIG['claude_model']})"
    )
    
    parser.add_argument(
        "--evolve", "-e",
        action="store_true",
        help="Use evolutionary optimization"
    )
    
    parser.add_argument(
        "--generations",
        type=int,
        default=5,
        help="Evolution generations (default: 5)"
    )
    
    parser.add_argument(
        "--output", "-o",
        type=str,
        default=DEFAULT_CONFIG["output_dir"],
        help=f"Output directory (default: {DEFAULT_CONFIG['output_dir']})"
    )
    
    parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="Minimal output"
    )
    
    parser.add_argument(
        "--no-save",
        action="store_true",
        help="Don't save output to file"
    )
    
    parser.add_argument(
        "--sync", "-s",
        action="store_true",
        help="Sync ElderPlinus payloads from GitHub before running"
    )
    
    parser.add_argument(
        "--version", "-v",
        action="version",
        version=f"PromptShot v{VERSION}"
    )
    
    return parser.parse_args()


def main():
    """Main entry point."""
    args = parse_args()
    
    # Print banner unless quiet mode
    if not args.quiet:
        print_banner()
        print_api_status()
    
    # Run pipeline
    try:
        result = run_pipeline(
            goal=args.goal,
            threshold=args.threshold,
            max_rounds=args.rounds,
            mutation_depth=args.mutations,
            gpt_model=args.gpt_model,
            claude_model=args.claude_model,
            output_dir=args.output,
            verbose=not args.quiet,
            use_evolution=args.evolve,
            evolution_generations=args.generations,
            save_output=not args.no_save,
            sync_payloads=args.sync,
        )
        
        # Exit code based on success
        sys.exit(0 if result.success else 1)
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Interrupted by user")
        sys.exit(130)
    
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        if not args.quiet:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()